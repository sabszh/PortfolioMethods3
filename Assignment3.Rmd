---
title: "A3_Machine-learning.Rmd"
output: html_document
date: "2022-11-02"
---

# Assignment 3 - Machine learning

The Machine Learning assignment has 3 main parts: First we create a skeptical and an informed simulation, based on the meta-analysis. Second we build and test our machine learning pipeline on the simulated data. Second we apply the pipeline to the empirical data.

The report for the exam, thus, consists of the answer to all the following prompts:
- Describe your machine learning pipeline. Produce a diagram of it to guide the reader (e.g. see Rybner et al 2022 Vocal markers of autism: Assessing the generalizability of ML models), and describe the different parts: data budgeting, data preprocessing, model choice and training, assessment of performance.
- Briefly justify and describe your use of simulated data, and results from the pipeline on them.
- Describe results from applying the ML pipeline to the empirical data and what can we learn from them.

Remember: plots are very very important to communicate your process and results.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
### Loading packages
```{r}
pacman::p_load(tidyverse,tidybayes,brms,ggplot2,bayesplot,rstan,gridExtra,grid,dplyr,cmdstanr,msm,metafor,janitor,ggridges,glue,stringr,forcats,tidymodels,ggview,melt)

# install.packages("remotes")
#remotes::install_github("stan-dev/cmdstanr")

#cmdstanr::install_cmdstan()
```

## Part I - Simulating data

Use the meta-analysis reported in Parola et al (2020),
- create a simulated dataset with 100 matched pairs of schizophrenia and controls
- each participant producing 10 repeated measures (10 trials with their speech recorded).
- for each of these "recordings" (data points) produce 10 acoustic measures:
- 6 from the meta-analysis,
- 4 with just random noise.

Do the same for a baseline dataset including only 10 noise variables. Tip: see the slides for the code. 

### Simulating the data
```{r}
# First define population size
set.seed(169)
n <- 100
trials <- 10


# Define the different effect sizes
InformedEffectMean <- c(0.25,-0.55,-0.75,-1.26,0.05,1.89,0,0,0,0)
SkepticalEffectMean <- rep(0,10)


# Then we define individual variability from population and across trails and measurement error
IndividualSD <- 1
TrialSD <- 0.5
Error <- 0.2


# For each pair of participants we need to identify the true effect size for each variable

for (i in seq(10)){
  temp_informed <- tibble(
    ID = seq(n),
    TrueEffect = rnorm(n,InformedEffectMean[i],IndividualSD),
    Variable = paste0("v",i))
  temp_skeptic <- tibble(
    ID = seq(n),
    TrueEffect = rnorm(n,SkepticalEffectMean[i],IndividualSD),
    Variable = paste0("v",i))
  if (i == 1) {
    d_informed_true <- temp_informed
    d_skeptic_true <- temp_skeptic

  } else {
    d_informed_true <- rbind(d_informed_true,temp_informed)
    d_skeptic_true <- rbind(d_skeptic_true,temp_skeptic)
    }
}

```


```{r}
# Create tibble with one row per trial
d_trial <- tibble(expand_grid(ID = seq(n),Trial = seq(trials),Group = c("Schizophrenia","Control")))

d_informed <- merge(d_informed_true,d_trial)
d_skeptic <- merge(d_skeptic_true,d_trial)

d_informed$Variable[d_informed$Variable=="v1"] <- "Pitch_mode"
d_informed$Variable[d_informed$Variable=="v2"] <- "Pitch_vari"
d_informed$Variable[d_informed$Variable=="v3"] <- "Speech_rate"
d_informed$Variable[d_informed$Variable=="v4"] <- "Prop_spokenT"
d_informed$Variable[d_informed$Variable=="v5"] <- "Pause_n"
d_informed$Variable[d_informed$Variable=="v6"] <- "Pause_len"
d_informed$Variable[d_informed$Variable=="v7"] <- "Noise1"
d_informed$Variable[d_informed$Variable=="v8"] <- "Noise2"
d_informed$Variable[d_informed$Variable=="v9"] <- "Noise3"
d_informed$Variable[d_informed$Variable=="v10"] <- "Noise4"

d_skeptic$Variable[d_skeptic$Variable=="v1"] <- "Pitch_mode"
d_skeptic$Variable[d_skeptic$Variable=="v2"] <- "Pitch_vari"
d_skeptic$Variable[d_skeptic$Variable=="v3"] <- "Speech_rate"
d_skeptic$Variable[d_skeptic$Variable=="v4"] <- "Prop_spokenT"
d_skeptic$Variable[d_skeptic$Variable=="v5"] <- "Pause_n"
d_skeptic$Variable[d_skeptic$Variable=="v6"] <- "Pause_len"
d_skeptic$Variable[d_skeptic$Variable=="v7"] <- "Noise1"
d_skeptic$Variable[d_skeptic$Variable=="v8"] <- "Noise2"
d_skeptic$Variable[d_skeptic$Variable=="v9"] <- "Noise3"
d_skeptic$Variable[d_skeptic$Variable=="v10"] <- "Noise4"

for (i in seq(nrow(d_informed))){
  d_informed$measurement[i] <- ifelse(d_informed$Group[i]=="Schizophrenia",
                                      rnorm(1,rnorm(1,d_informed$TrueEffect[i]/2,TrialSD),Error),
                                      rnorm(1,rnorm(1,(-d_informed$TrueEffect[i])/2,TrialSD),Error))
  d_skeptic$measurement[i] <- ifelse(d_skeptic$Group[i]=="Schizophrenia",
                                      rnorm(1,rnorm(1,d_skeptic$TrueEffect[i]/2,TrialSD),Error),
                                      rnorm(1,rnorm(1,(-d_skeptic$TrueEffect[i])/2,TrialSD),Error))
}


d_informed_wide <- d_informed %>% 
  mutate(TrueEffect = NULL) %>% 
  pivot_wider(names_from = Variable,
              values_from = measurement)

d_skeptic_wide <- d_skeptic %>% 
  mutate(TrueEffect = NULL) %>% 
  pivot_wider(names_from = Variable,
              values_from = measurement)
```
### Plotting simulated data
```{r}
densplotinformed <- ggplot(d_informed)  + 
  aes(x = measurement, fill = Group,alpha=.5)  + 
  geom_density(adjust = 1L)  + 
  scale_fill_hue(direction = 1)  + 
  theme_gray()  + 
  facet_wrap(vars(Variable), ncol = 2L)  + 
  guides(alpha = FALSE)  + 
  labs(title = "Informed effect mean") 

densplotskeptic <- ggplot(d_skeptic)  + 
  aes(x = measurement, fill = Group,alpha=.5)  + 
  geom_density(adjust = 1L)  + 
  scale_fill_hue(direction = 1)  + 
  theme_gray()  + 
  facet_wrap(vars(Variable), ncol = 2L)  + 
  guides(alpha = FALSE)  + 
  labs(title = "Skeptical effect mean") 

densplotinformed
densplotskeptic
```


## Part II - ML pipeline on simulated data

On the two simulated datasets (separately) build a machine learning pipeline:

i) create a data budget (e.g. balanced training and test sets);

ii) pre-process the data (e.g. scaling the features);

iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression);

iv) assess performance on the test set;

v) discuss whether performance is as expected and feature importance is as expected.

Bonus question: replace the bayesian multilevel regression with a different algorithm, e.g. SVM or random forest (but really, anything you'd like to try).

### Creating data budget
```{r}
# Creating a data budget for informed
TestID <- sample(seq(n),20)

train_informed <- d_informed_wide %>% 
  subset(!(ID %in% TestID))

test_informed <- d_informed_wide %>% 
  subset(ID %in% TestID)

# Creating a data budget for skeptical
train_skeptic <- d_skeptic_wide %>% 
  subset(!(ID %in% TestID))

test_skeptic <- d_skeptic_wide %>% 
  subset(ID %in% TestID)
```

### Pre-proccesing the data
```{r}
# Pre-processing the data
library(tidymodels)

rec_informed <- train_informed %>% 
  recipe(Group~.) %>% # defines the outcome
  step_scale("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len","Noise1","Noise2","Noise3","Noise4") %>% # scales numeric predictors
  step_center("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len","Noise1","Noise2","Noise3","Noise4") %>% # center numeric predictors
  prep(training = train_informed,retain=TRUE)

rec_skeptic <- train_skeptic %>% 
  recipe(Group ~ . ) %>% 
  step_scale("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len","Noise1","Noise2","Noise3","Noise4") %>% 
  step_center("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len","Noise1","Noise2","Noise3","Noise4") %>% 
  prep(training = train_skeptic,retain=TRUE)

# Apply recipe to train and test for informed
train_informed_s <- juice(rec_informed)
test_informed_s <- bake(rec_informed,new_data=test_informed)

# Apply recipe to train and test for skeptic
train_skeptic_s <- juice(rec_skeptic)
test_skeptic_s <- bake(rec_skeptic,new_data=test_skeptic)
```

### Fitting a classifcation algorithm on the traning data
```{r}
# fitting and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression)

# Formulas used for both models
Variables_f1 <- bf(Group~1 + Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len +  Noise1 + Noise2 + Noise3 + Noise4)

Variables_f2 <- bf(Group~1 + Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len +  Noise1 + Noise2 + Noise3 + Noise4 + (1|ID))

Variables_f3 <- bf(Group~1 + Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len +  Noise1 + Noise2 + Noise3 + Noise4 + (Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len + Noise1 + Noise2 + Noise3 + Noise4|ID))

# Get prior for informed
get_prior(Variables_f3,train_informed_s,family=bernoulli)

# Priors
Variables_p1 <- c(
  brms::prior(normal(0,1),class=Intercept),
  brms::prior(normal(0,1),class=b)
)

Variables_p2 <- c(
  brms::prior(normal(0,1),class=Intercept),
  brms::prior(normal(0,1),class=b),
  brms::prior(normal(0,.1),class=sd)
)

Variables_p3 <- c(
  brms::prior(normal(0,1),class=Intercept),
  brms::prior(normal(0,1),class=b),
  brms::prior(normal(0,.1),class=sd),
  brms::prior(lkj(1),class = cor),
  brms::prior(lkj(1),class = cor,group = ID)
)

Variables_m1i <- brm(
  Variables_f1,
  train_informed_s,
  family = bernoulli,
  prior = Variables_p1,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta=0.9,
                 max_treedepth = 20)
)

Variables_m2i <- brm(
  Variables_f2,
  train_informed_s,
  family = bernoulli,
  prior = Variables_p2,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta=0.9,
                 max_treedepth = 20)
)

Variables_m3i <- brm(
  Variables_f3,
  train_informed_s,
  family = bernoulli,
  prior = Variables_p3,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta=0.9,
                 max_treedepth = 20)
)

Variables_m1s <- brm(
  Variables_f1,
  train_skeptic_s,
  family = bernoulli,
  prior = Variables_p1,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta=0.9,
                 max_treedepth = 20)
)

Variables_m2s <- brm(
  Variables_f2,
  train_skeptic_s,
  family = bernoulli,
  prior = Variables_p2,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta=0.9,
                 max_treedepth = 20)
)

Variables_m3s <- brm(
  Variables_f3,
  train_skeptic_s,
  family = bernoulli,
  prior = Variables_p3,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta=0.9,
                 max_treedepth = 20)
)


inf1 <- pp_check(Variables_m1i, ndraws = 100)  +  labs(title="Pp-check informed, Fixed effects")
inf2 <- pp_check(Variables_m2i, ndraws = 100)  +  labs(title="Pp-check informed, Varrying intercepts")
inf3 <- pp_check(Variables_m3i, ndraws = 100)  +  labs(title="Pp-check informed, Varrying slopes")

ske1 <- pp_check(Variables_m1s, ndraws = 100)  +  labs(title="Pp-check skeptic, Fixed effects")
ske2 <- pp_check(Variables_m2s, ndraws = 100)  +  labs(title="Pp-check skeptic, Varrying intercepts")
ske3 <- pp_check(Variables_m3s, ndraws = 100)  +  labs(title="Pp-check skeptic, Varrying slopes")

grid.arrange(inf1,ske1,inf2,ske2,inf3, ske3,nrow=3,ncol = 2)
```

### Doing the fit, posterior
```{r}
Variables_fit1i<-
  brm(
    Variables_f1,
    train_informed_s,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = Variables_p1,
    file = "Variables_fit1i",
    #refit = "on_change",
    sample_prior = T,
    iter = 5000, 
    warmup = 2000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ),
    stan_model_args=list(stanc_options = list("O1"))
  )

Variables_fit2i<-
  brm(
    Variables_f2,
    train_informed_s,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = Variables_p2,
    file = "Variables_fit2i",
    #refit = "on_change",
    sample_prior = T,
    iter = 5000, 
    warmup = 2000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ),
    stan_model_args=list(stanc_options = list("O1"))
  )

Variables_fit3i<-
  brm(
    Variables_f3,
    train_informed_s,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = Variables_p3,
    file = "Variables_fit3i",
    #refit = "on_change",
    sample_prior = T,
    iter = 5000, 
    warmup = 2000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ),
    stan_model_args=list(stanc_options = list("O1"))
  )

Variables_fit1s<-
  brm(
    Variables_f1,
    train_skeptic_s,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = Variables_p1,
    file = "Variables_fit1s",
    #refit = "on_change",
    sample_prior = T,
    iter = 5000, 
    warmup = 2000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ),
    stan_model_args=list(stanc_options = list("O1"))
  )

Variables_fit2s<-
  brm(
    Variables_f2,
    train_skeptic_s,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = Variables_p2,
    file = "Variables_fit2s",
    #refit = "on_change",
    sample_prior = T,
    iter = 5000, 
    warmup = 2000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ),
    stan_model_args=list(stanc_options = list("O1"))
  )

Variables_fit3s<-
  brm(
    Variables_f3,
    train_informed_s,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = Variables_p3,
    file = "Variables_fit3s",
    #refit = "on_change",
    sample_prior = T,
    iter = 5000, 
    warmup = 2000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ),
    stan_model_args=list(stanc_options = list("O1"))
  )
```

### Plots drawing from posterior, posterior update plots
```{r}
posterior1i <- as_draws_df(Variables_fit1i)
posterior2i <- as_draws_df(Variables_fit2i)
posterior3i <- as_draws_df(Variables_fit3i)

posterior1s <- as_draws_df(Variables_fit1s)
posterior2s <- as_draws_df(Variables_fit2s)
posterior3s <- as_draws_df(Variables_fit3s)

# Posterior for the informed
postinf1 <- ggplot(posterior1i)  + 
  geom_density(aes(b_Intercept),fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_Intercept), fill="red", alpha=0.3) + 
  labs(title = "intercept, model 1")
  theme_minimal()

postinf2 <-ggplot(posterior1i)  + 
  geom_density(aes(prior_b), fill="red")  + 
  geom_density(aes(b_Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(b_Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(b_Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(b_Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(b_Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(b_Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(b_Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(b_Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(b_Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "b, model 1")  + 
  theme_minimal()

postinf3 <-ggplot(posterior2i)  + 
  geom_density(aes(b_Intercept),fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_Intercept), fill="red", alpha=0.3) + 
  labs(title = "intercept, model 2")
  theme_minimal()

postinf4 <-ggplot(posterior2i)  + 
  geom_density(aes(sd_ID__Intercept), fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_sd_ID), fill="red", alpha=0.3)  + 
  labs(title = "SD, model 2")  + 
  theme_minimal()

postinf5 <-ggplot(posterior2i)  + 
  geom_density(aes(prior_b), fill="red")  + 
  geom_density(aes(b_Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(b_Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(b_Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(b_Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(b_Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(b_Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(b_Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(b_Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(b_Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "b, model 2")  + 
  theme_minimal()

postinf6 <-ggplot(posterior3i)  + 
  geom_density(aes(b_Intercept),fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_Intercept), fill="red", alpha=0.3) + 
  labs(title = "intercept, model 3")
  theme_minimal()

postinf7 <-ggplot(posterior3i)  + 
  geom_density(aes(sd_ID__Intercept), fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_sd_ID), fill="red", alpha=0.3)  + 
  labs(title = "SD, model 3")  + 
  theme_minimal()

postinf8 <-ggplot(posterior3i)  + 
  geom_density(aes(prior_b), fill="red")  + 
  geom_density(aes(b_Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(b_Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(b_Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(b_Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(b_Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(b_Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(b_Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(b_Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(b_Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "b, model 3")  + 
  theme_minimal()

postinf9 <- ggplot(posterior3i)  + 
  geom_density(aes(prior_sd_ID), fill="red")  + 
  geom_density(aes(sd_ID__Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(sd_ID__Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(sd_ID__Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(sd_ID__Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(sd_ID__Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "sd for ID, model 3")  + 
  theme_minimal()

# Posterior for the skeptic
postske1 <- ggplot(posterior1s)  + 
  geom_density(aes(b_Intercept),fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_Intercept), fill="red", alpha=0.3) + 
  labs(title = "intercept, model 1")
  theme_minimal()

postske2 <- ggplot(posterior1s)  + 
  geom_density(aes(prior_b), fill="red")  + 
  geom_density(aes(b_Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(b_Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(b_Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(b_Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(b_Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(b_Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(b_Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(b_Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(b_Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "b, model 1")  + 
  theme_minimal()

postske3 <- ggplot(posterior2s)  + 
  geom_density(aes(b_Intercept),fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_Intercept), fill="red", alpha=0.3) + 
  labs(title = " intercept, model 2")
  theme_minimal()

postske4 <- ggplot(posterior2s)  + 
  geom_density(aes(sd_ID__Intercept), fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_sd_ID), fill="red", alpha=0.3)  + 
  labs(title = "SD, model 2")  + 
  theme_minimal()

postske5 <- ggplot(posterior2s)  + 
  geom_density(aes(prior_b), fill="red")  + 
  geom_density(aes(b_Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(b_Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(b_Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(b_Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(b_Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(b_Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(b_Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(b_Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(b_Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "b, model 2")  + 
  theme_minimal()

postske6 <- ggplot(posterior3s)  + 
  geom_density(aes(b_Intercept),fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_Intercept), fill="red", alpha=0.3) + 
  labs(title = "intercept, model 3")
  theme_minimal()

postske7 <- ggplot(posterior3s)  + 
  geom_density(aes(sd_ID__Intercept), fill="blue", alpha=0.3)  + 
  geom_density(aes(prior_sd_ID), fill="red", alpha=0.3)  + 
  labs(title = "SD, model 3")  + 
  theme_minimal()

postske8 <- ggplot(posterior3s)  + 
  geom_density(aes(prior_b), fill="red")  + 
  geom_density(aes(b_Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(b_Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(b_Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(b_Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(b_Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(b_Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(b_Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(b_Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(b_Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "b,  model 3")  + 
  theme_minimal()

postske9 <- ggplot(posterior3s)  + 
  geom_density(aes(prior_sd_ID), fill="red")  + 
  geom_density(aes(sd_ID__Pitch_mode), fill="blue", alpha=0.3)  + 
  geom_density(aes(sd_ID__Pitch_vari), fill="salmon", alpha=0.3)  + 
  geom_density(aes(sd_ID__Speech_rate), fill="orange", alpha=0.3)  + 
  geom_density(aes(sd_ID__Prop_spokenT), fill="purple", alpha=0.3)  + 
  geom_density(aes(sd_ID__Pause_n), fill="pink", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise1), fill="green", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise2), fill="yellow", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise3), fill="black", alpha=0.3)  + 
  geom_density(aes(sd_ID__Noise4), fill="grey", alpha=0.3)  + 
  labs(title = "sd for ID, model 3")  + 
  theme_minimal()

grid.arrange(postinf1,postinf2,postinf3,postinf4,postinf5,postinf6,postinf7,postinf8,postinf9,top = "Posterior for informed")
grid.arrange(postske1,postske2,postske3,postske4,postske5,postske6,postske7,postske8,postske9,top = "Posterior for skeptic")
```


### Sensitivy analysis if had time
```{r}

```

### Generating average predictions
```{r}
# generate average predictions 
# informed for the trained dataset
# fixed effect
train_informed_s$PredictionsPerc1 <- predict(Variables_fit1i)[, 1]
train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 <= 0.5] <- "Control"

#vary intercept
train_informed_s$PredictionsPerc2 <- predict(Variables_fit2i)[, 1]
train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 <= 0.5] <- "Control"

#vary slopes
train_informed_s$PredictionsPerc3 <- predict(Variables_fit3i)[, 1]
train_informed_s$Predictions3[train_informed_s$PredictionsPerc3 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions3[train_informed_s$PredictionsPerc3 <= 0.5] <- "Control"


train_informed_s <- train_informed_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions1 = as.factor(Predictions1),
    Predictions2 = as.factor(Predictions2),
    Predictions3 = as.factor(Predictions3)
  )

train_informed_s

# generate average predictions 
### skeptic
##for the trained dataset

# fixed effect
train_skeptic_s$PredictionsPerc1 <- predict(Variables_fit1s)[, 1]
train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 <= 0.5] <- "Control"

#vary intercept
train_skeptic_s$PredictionsPerc2 <- predict(Variables_fit2i)[, 1]
train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 <= 0.5] <- "Control"

#vary slopes
train_skeptic_s$PredictionsPerc3 <- predict(Variables_fit3i)[, 1]
train_skeptic_s$Predictions3[train_skeptic_s$PredictionsPerc3 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions3[train_skeptic_s$PredictionsPerc3 <= 0.5] <- "Control"


train_skeptic_s <- train_skeptic_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions1 = as.factor(Predictions1),
    Predictions2 = as.factor(Predictions2),
    Predictions3 = as.factor(Predictions3)
  )

train_skeptic_s
```
### Generate average predictions for informed
```{r}
# generate average predictions 
# informed for the trained dataset
# fixed effect
train_informed_s$PredictionsPerc1 <- predict(Variables_fit1i)[, 1]
train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 <= 0.5] <- "Control"

#vary intercept
train_informed_s$PredictionsPerc2 <- predict(Variables_fit2i)[, 1]
train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 <= 0.5] <- "Control"

#vary slopes
train_informed_s$PredictionsPerc3 <- predict(Variables_fit3i)[, 1]
train_informed_s$Predictions3[train_informed_s$PredictionsPerc3 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions3[train_informed_s$PredictionsPerc3 <= 0.5] <- "Control"


train_informed_s <- train_informed_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions1 = as.factor(Predictions1),
    Predictions2 = as.factor(Predictions2),
    Predictions3 = as.factor(Predictions3)
  )

train_informed_s

# generate average predictions 
### informed
##for the test dataset

# fixed effect
test_informed_s$PredictionsPerc1 <- predict(Variables_fit1s,newdata = test_informed_s,allow_new_levels = T)[, 1]
test_informed_s$Predictions1[test_informed_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
test_informed_s$Predictions1[test_informed_s$PredictionsPerc1 <= 0.5] <- "Control"

#vary intercept
test_informed_s$PredictionsPerc2 <- predict(Variables_fit2s,newdata = test_informed_s,allow_new_levels = T)[, 1]
test_informed_s$Predictions2[test_informed_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
test_informed_s$Predictions2[test_informed_s$PredictionsPerc2 <= 0.5] <- "Control"

#vary slopes
test_informed_s$PredictionsPerc3 <- predict(Variables_fit3s,newdata = test_informed_s,allow_new_levels = T)[, 1]
test_informed_s$Predictions3[test_informed_s$PredictionsPerc3 > 0.5] <- "Schizophrenia"
test_informed_s$Predictions3[test_informed_s$PredictionsPerc3 <= 0.5] <- "Control"


test_informed_s <- test_informed_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions1 = as.factor(Predictions1),
    Predictions2 = as.factor(Predictions2),
    Predictions3 = as.factor(Predictions3)
  )

test_informed_s
```

```{r}
# generate average predictions 
# skeptic for the trained dataset
# fixed effect
train_skeptic_s$PredictionsPerc1 <- predict(Variables_fit1i)[, 1]
train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 <= 0.5] <- "Control"

#vary intercept
train_skeptic_s$PredictionsPerc2 <- predict(Variables_fit2i)[, 1]
train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 <= 0.5] <- "Control"

#vary slopes
train_skeptic_s$PredictionsPerc3 <- predict(Variables_fit3i)[, 1]
train_skeptic_s$Predictions3[train_skeptic_s$PredictionsPerc3 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions3[train_skeptic_s$PredictionsPerc3 <= 0.5] <- "Control"


train_skeptic_s <- train_skeptic_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions1 = as.factor(Predictions1),
    Predictions2 = as.factor(Predictions2),
    Predictions3 = as.factor(Predictions3)
  )

train_skeptic_s

# generate average predictions 
### skeptic
##for the trained dataset

# fixed effect
test_skeptic_s$PredictionsPerc1 <- predict(Variables_fit1s,newdata = test_skeptic_s,allow_new_levels = T)[, 1]
test_skeptic_s$Predictions1[test_skeptic_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
test_skeptic_s$Predictions1[test_skeptic_s$PredictionsPerc1 <= 0.5] <- "Control"

#vary intercept
test_skeptic_s$PredictionsPerc2 <- predict(Variables_fit2s,newdata = test_skeptic_s,allow_new_levels = T)[, 1]
test_skeptic_s$Predictions2[test_skeptic_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
test_skeptic_s$Predictions2[test_skeptic_s$PredictionsPerc2 <= 0.5] <- "Control"

#vary slopes
test_skeptic_s$PredictionsPerc3 <- predict(Variables_fit3s,newdata = test_skeptic_s,allow_new_levels = T)[, 1]
test_skeptic_s$Predictions3[test_skeptic_s$PredictionsPerc3 > 0.5] <- "Schizophrenia"
test_skeptic_s$Predictions3[test_skeptic_s$PredictionsPerc3 <= 0.5] <- "Control"


test_skeptic_s <- test_skeptic_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions1 = as.factor(Predictions1),
    Predictions2 = as.factor(Predictions2),
    Predictions3 = as.factor(Predictions3)
  )

test_skeptic_s
```

### Assesing average performance
```{r}
# Assessing average performance for informed
conf_mat(
  train_informed_s,
  truth = Group,
  estimate = Predictions1,
  dnn = c("Prediction","Truth")
)

metrics(train_informed_s,
        truth = Group,
        estimate = Predictions1) %>% 
  knitr::kable()

conf_mat(
  train_informed_s,
  truth = Group,
  estimate = Predictions2,
  dnn = c("Prediction","Truth")
)

metrics(train_informed_s,
        truth = Group,
        estimate = Predictions2) %>% 
  knitr::kable()

conf_mat(
  train_informed_s,
  truth = Group,
  estimate = Predictions3,
  dnn = c("Prediction","Truth")
)

metrics(train_informed_s,
        truth = Group,
        estimate = Predictions3) %>% 
  knitr::kable()

## For test
metrics(test_informed_s,
        truth = Group,
        estimate = Predictions1) %>% 
  knitr::kable()

metrics(test_informed_s,
        truth = Group,
        estimate = Predictions2) %>% 
  knitr::kable()

metrics(test_informed_s,
        truth = Group,
        estimate = Predictions3) %>% 
  knitr::kable()


# Assessing average performance for skeptic
conf_mat(
  train_skeptic_s,
  truth = Group,
  estimate = Predictions1,
  dnn = c("Prediction","Truth")
)

metrics(train_skeptic_s,
        truth = Group,
        estimate = Predictions1) %>% 
  knitr::kable()

conf_mat(
  train_skeptic_s,
  truth = Group,
  estimate = Predictions2,
  dnn = c("Prediction","Truth")
)

metrics(train_skeptic_s,
        truth = Group,
        estimate = Predictions2) %>% 
  knitr::kable()

conf_mat(
  train_skeptic_s,
  truth = Group,
  estimate = Predictions3,
  dnn = c("Prediction","Truth")
)

metrics(train_skeptic_s,
        truth = Group,
        estimate = Predictions3) %>% 
  knitr::kable()

## For test
metrics(train_skeptic_s,
        truth = Group,
        estimate = Predictions1) %>% 
  knitr::kable()

metrics(train_skeptic_s,
        truth = Group,
        estimate = Predictions2) %>% 
  knitr::kable()

metrics(train_skeptic_s,
        truth = Group,
        estimate = Predictions3) %>% 
  knitr::kable()
```
### Calculating uncertainity 
```{r}
## Now with uncertainty
pacman::p_load(tidyverse)

PerformanceProb <- tibble(expand_grid(
  Sample = seq(5000),
  Model = c("FixedEffects","VaryingIntercept","VariyingSlope"),
  Setup = c("informed","skeptic"),
  Type = c("training","test"))
)
# posterior predict for training informed and skeptic

train1i <- inv_logit_scaled(posterior_linpred(Variables_fit1i,summary = F))
train2i <- inv_logit_scaled(posterior_linpred(Variables_fit2i,summary = F))
train3i <- inv_logit_scaled(posterior_linpred(Variables_fit3i,summary = F))

train1s <- inv_logit_scaled(posterior_linpred(Variables_fit1s,summary = F))
train2s <- inv_logit_scaled(posterior_linpred(Variables_fit2s,summary = F))
train3s <- inv_logit_scaled(posterior_linpred(Variables_fit3s,summary = F))

# same but for test
test1i <- inv_logit_scaled(posterior_linpred(Variables_fit1i,summary = F, newdata = test_informed_s,allow_new_levels = T))
test2i <- inv_logit_scaled(posterior_linpred(Variables_fit2i,summary = F, newdata = test_informed_s,allow_new_levels = T))
test3i <- inv_logit_scaled(posterior_linpred(Variables_fit3i,summary = F, newdata = test_informed_s,allow_new_levels = T))

test1s <- inv_logit_scaled(posterior_linpred(Variables_fit1s,summary = F, newdata = test_skeptic_s,allow_new_levels = T))
test2s <- inv_logit_scaled(posterior_linpred(Variables_fit2s,summary = F, newdata = test_skeptic_s,allow_new_levels = T))
test3s <- inv_logit_scaled(posterior_linpred(Variables_fit3s,summary = F, newdata = test_skeptic_s,allow_new_levels = T))

for (i in seq(5000)){
  # inserting the predictions into the df for informed and skeptic
  train_informed_s$Predictions1 <- as.factor(ifelse(train1i[i,] > 0.5, "Schizophrenia","Control"))
  train_informed_s$Predictions2 <- as.factor(ifelse(train2i[i,] > 0.5, "Schizophrenia","Control"))
  train_informed_s$Predictions3 <- as.factor(ifelse(train3i[i,] > 0.5, "Schizophrenia","Control"))

  test_informed_s$Predictions1 <- as.factor(ifelse(test1i[i,] > 0.5, "Schizophrenia","Control"))
  test_informed_s$Predictions2 <- as.factor(ifelse(test2i[i,] > 0.5, "Schizophrenia","Control"))
  test_informed_s$Predictions3 <- as.factor(ifelse(test3i[i,] > 0.5, "Schizophrenia","Control"))
  
  train_skeptic_s$Predictions1 <- as.factor(ifelse(train1s[i,] > 0.5, "Schizophrenia","Control"))
  train_skeptic_s$Predictions2 <- as.factor(ifelse(train2s[i,] > 0.5, "Schizophrenia","Control"))
  train_skeptic_s$Predictions3 <- as.factor(ifelse(train3s[i,] > 0.5, "Schizophrenia","Control"))

  test_skeptic_s$Predictions1 <- as.factor(ifelse(test1s[i,] > 0.5, "Schizophrenia","Control"))
  test_skeptic_s$Predictions2 <- as.factor(ifelse(test2s[i,] > 0.5, "Schizophrenia","Control"))
  test_skeptic_s$Predictions3 <- as.factor(ifelse(test3s[i,] > 0.5, "Schizophrenia","Control"))
  
  # put it into the performance prob df
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "FixedEffects" & PerformanceProb$Setup == "informed" & PerformanceProb$Type == "training"] <- accuracy(train_informed_s,truth = Group, estimate = Predictions1)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept" & PerformanceProb$Setup == "informed" & PerformanceProb$Type == "training"] <- accuracy(train_informed_s,truth = Group, estimate = Predictions2)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VariyingSlope" & PerformanceProb$Setup == "informed" & PerformanceProb$Type == "training"] <- accuracy(train_informed_s,truth = Group, estimate = Predictions3)[,".estimate"]
  
  
   PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "FixedEffects" & PerformanceProb$Setup == "skeptic" & PerformanceProb$Type == "training"] <- accuracy(train_skeptic_s,truth = Group, estimate = Predictions1)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept" & PerformanceProb$Setup == "skeptic" & PerformanceProb$Type == "training"] <- accuracy(train_skeptic_s,truth = Group, estimate = Predictions2)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VariyingSlope" & PerformanceProb$Setup == "skeptic" & PerformanceProb$Type == "training"] <- accuracy(train_skeptic_s,truth = Group, estimate = Predictions3)[,".estimate"]
  
  # the same for tests
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "FixedEffects" & PerformanceProb$Setup == "informed" & PerformanceProb$Type == "test"] <- accuracy(test_informed_s,truth = Group, estimate = Predictions1)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept" & PerformanceProb$Setup == "informed" & PerformanceProb$Type == "test"] <- accuracy(test_informed_s,truth = Group, estimate = Predictions2)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VariyingSlope" & PerformanceProb$Setup == "informed" & PerformanceProb$Type == "test"] <- accuracy(test_informed_s,truth = Group, estimate = Predictions3)[,".estimate"]
  
  
   PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "FixedEffects" & PerformanceProb$Setup == "skeptic" & PerformanceProb$Type == "test"] <- accuracy(test_skeptic_s,truth = Group, estimate = Predictions1)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept" & PerformanceProb$Setup == "skeptic" & PerformanceProb$Type == "test"] <- accuracy(test_skeptic_s,truth = Group, estimate = Predictions2)[,".estimate"]
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VariyingSlope" & PerformanceProb$Setup == "skeptic" & PerformanceProb$Type == "test"] <- accuracy(test_skeptic_s,truth = Group, estimate = Predictions3)[,".estimate"]
  
}

PerformanceProb$Accuracy <- as.numeric(PerformanceProb$Accuracy)
```
### Plot of uncertainity of performance probablity of the different models
```{r}
ggplot(PerformanceProb)  + 
  aes(x = Model, y = Accuracy, colour = Type)  + 
  facet_wrap(~Setup)  + 
  geom_point(shape=16,position = position_dodge(width = 0.5))  + 
  scale_color_hue(direction = 1)  + 
  theme_grey()
```



### Feature importance
```{r}
pacman::p_load(DALEX,DALEXtra,kernlab,randomForest,xgboost,knitr,dotwhisker)

d_inf <- train_informed_s %>% 
  mutate(Trial = NULL,Preds = NULL,
         Predictions1 = NULL,PredictionsPerc1 = NULL,
         Predictions2 = NULL,PredictionsPerc2 = NULL,
         Predictions3 = NULL,PredictionsPerc3 = NULL)

LogisticRegression_inf <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Group~1 + Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len +  Noise1 + Noise2 + Noise3 + Noise4 + (Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len + Noise1 + Noise2 + Noise3 + Noise4|ID),data = d_inf)

explainer_lm <- 
  explain_tidymodels(
    LogisticRegression_inf,
    data = train_informed_s,
    y = as.numeric(train_informed_s$Group) - 1,
    label = "logReg",
    verbose = FALSE
  )

lm_plot <- explainer_lm %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE)  +  
  ggtitle("Feature Importance","")
```

```{r}
RandomForest_inf <- rand_forest() %>% 
  set_mode("classification") %>% 
  set_engine("randomForest") %>% 
  fit(Group~1 + Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len +  Noise1 + Noise2 + Noise3 + Noise4 + (Pitch_mode + Pitch_vari + Speech_rate + Prop_spokenT + Pause_n + Pause_len + Noise1 + Noise2 + Noise3 + Noise4|ID),data = d_inf)

explainer_rf <- 
  explain_tidymodels(
    RandomForest_inf,
    data = train_informed_s,
    y = as.numeric(train_informed_s$Group) - 1,
    label = "random forest",
    verbose = FALSE
  )

rf_plot <- explainer_rf %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE)  + 
  ggtitle("Feature Importance","")
```

```{r}
grid.arrange(lm_plot,rf_plot,nrow=1)
```
```{r}
model_profile_lm1 <- model_profile(explainer_lm,type="partial",
                                   variables = c("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len", "Noise1","Noise2","Noise3","Noise4"))

plot(model_profile_lm1,variables =c("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len", "Noise1","Noise2","Noise3","Noise4")) + 
  ggtitle("Partial dependence profile","")

model_profile_lm2 <- model_profile(explainer_rf,type="partial",
                                   variables = c("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len", "Noise1","Noise2","Noise3","Noise4"))

plot(model_profile_lm2,variables =c("Pitch_mode","Pitch_vari","Speech_rate","Prop_spokenT","Pause_n","Pause_len", "Noise1","Noise2","Noise3","Noise4")) + 
  ggtitle("Partial dependence profile","")

```


## Part III - Applying the ML pipeline to empirical data

Download the empirical dataset from brightspace and apply your ML pipeline to the new data, adjusting where needed.

Warning: in the simulated dataset we only had 10 features, now you have many more! Such is the life of the ML practitioner. Consider the impact a higher number of features will have on your ML inference, and decide whether you need to cut down the number of features before running the pipeline (or alternatively expand the pipeline to add feature selection).

### Reading in the data
```{r}
EDf <- read_csv("Ass3_empiricalData1.csv")

head(EDf)
```

### Summarizing
```{r}
EDf%>% 
  subset(Trial=="T1") %>% 
  filter(Gender=="M"|Gender=="F",Diagnosis=="CT"|Diagnosis=="SCZ") %>% 
  group_by(Gender,Diagnosis) %>% 
  summarise(n=length(unique(NewID)))
```

### Creating a data budget
```{r}
pacman::p_load(groupdata2)
# Creating a data budget
EDf <- subset(EDf,select=c(-Gender,-PatID,-Trial,-Corpus,-Language))

EDf$NewID <- factor(EDf$NewID,levels=unique(EDf$NewID))
EDf$Diagnosis <- as.factor(EDf$Diagnosis)

head(EDf)
```

```{r}
set.seed(1373)
partitions <- partition(EDf,p = 0.2,id_col="NewID",cat_col = "Diagnosis")

trainDf <- partitions[[2]]
testDf <- partitions[[1]]

rec_EDf <- trainDf %>% 
  recipe(Diagnosis ~ . ) %>% 
  update_role(NewID, Diagnosis, new_role = "NewID") %>%
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_zv(all_predictors()) %>%
  step_corr(all_predictors(), threshold = 0.8) %>% 
  prep(training=trainDf,retain=TRUE)

# Apply recipe to train and test
trainEDf <- juice(rec_EDf)
testEDf <- bake(rec_EDf,new_data = testDf)

trainEDf$NewID <- as.integer(trainEDf$NewID)
testEDf$NewID <- as.integer(testEDf$NewID)
```

### Feature selection
```{r}
pacman::p_load(DALEX,DALEXtra,kernlab,randomForest,xgboost,knitr,dotwhisker,ggcorrplot,gam)
set.seed(21983)
d_edf <- trainEDf %>% 
  mutate(Trial = NULL,PatID = NULL,Language = NULL, Gender = NULL, Corpus = NULL)

LogisticRegression_inf_edf <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Diagnosis ~ 1  +  .  +  (1|NewID),data = d_edf)

explainer_lm_edf <- 
  explain_tidymodels(
    LogisticRegression_inf_edf,
    data = d_edf,
    y = as.numeric(d_edf$Diagnosis) - 1,
    label = "logReg",
    verbose = FALSE
  )

fi_plot <- explainer_lm_edf %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE)  +  
  ggtitle("Feature Importance","")
```

```{r}
SVM_inf_edf <- svm_rbf() %>% 
  set_mode("classification") %>% 
  set_engine("kernlab") %>% 
  fit(Diagnosis ~ 1  +  .  +  (1|NewID),data = d_edf)

RandomForest_inf_edf <- rand_forest() %>% 
  set_mode("classification") %>% 
  set_engine("randomForest") %>% 
  fit(Diagnosis ~ 1  +  .  +  (1|NewID),data = d_edf)

BoostedTree_inf_edf <- boost_tree() %>% 
  set_mode("classification") %>% 
  set_engine("xgboost") %>% 
  fit(Diagnosis ~ 1  +  .  +  (1|NewID),data = d_edf)

explainer_svm_edf <- 
  explain_tidymodels(
    SVM_inf_edf,
    data = d_edf,
    y = as.numeric(d_edf$Diagnosis) - 1,
    label = "support vector machine",
    verbose = FALSE
  )

explainer_rf_edf <- 
  explain_tidymodels(
    RandomForest_inf_edf,
    data = d_edf,
    y = as.numeric(d_edf$Diagnosis) - 1,
    label = "random forest",
    verbose = FALSE
  )

explainer_bt_edf <- 
  explain_tidymodels(
    BoostedTree_inf_edf,
    data = d_edf,
    y = as.numeric(d_edf$Diagnosis) - 1,
    label = "boosted trees",
    verbose = FALSE
  )

svm_plot <- explainer_svm_edf %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE)  +  
  ggtitle("Feature Importance, svm","")

rf_plot <- explainer_rf_edf %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE)  +  
  ggtitle("Feature Importance, rf","")

bt_plot <- explainer_bt_edf %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE)  +  
  ggtitle("Feature Importance, bt","")

```

```{r}
fi_plot
svm_plot
bt_plot
```

### Fitting a classifcation algorithm on the traning data 
```{r}
library(brms)
# fitting and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression)

# Formula logreg
FormulaDf_0lr <- bf(Diagnosis ~ 1 + Clarity_Mean + MCEP1_Median + MCEP1_SD + NewID + peakSlope_SD + MCEP8_Mean + HarmonicProductSpectrum_Mean + F0_Mean_Praat + MCEP6_Mean + HMPDD0_MAD + Rd_conf_Median + MCEP5_Mean + MCEP13_Mean + MCEP0_SD + peakSlope_IQR + HMPDD7_Median + Srh2_SD + Intensity_SD_Praat + MeanPauseDur_Cova + MCEP12_Median + F1_IQR + HMPDD6_Mean + TurnDuration_Cova + Intensity_Mean_Praat + MCEP4_Median + HMPDD0_SD + Rd_Mean + PauseNumMin_Praat + MCEP15_Mean + PauseDuration_Praat + (1|NewID))

FormulaDf_1lr <- bf(Diagnosis~1  +  Clarity_Mean + MCEP1_Median + MCEP1_SD + NewID + peakSlope_SD + MCEP8_Mean + HarmonicProductSpectrum_Mean + F0_Mean_Praat + MCEP6_Mean + HMPDD0_MAD + Rd_conf_Median + MCEP5_Mean + MCEP13_Mean + MCEP0_SD + peakSlope_IQR + HMPDD7_Median + Srh2_SD + Intensity_SD_Praat + MeanPauseDur_Cova + MCEP12_Median + F1_IQR + HMPDD6_Mean + TurnDuration_Cova + Intensity_Mean_Praat + MCEP4_Median + HMPDD0_SD + Rd_Mean + PauseNumMin_Praat + MCEP15_Mean + PauseDuration_Praat + MCEP8_IQR + MCEP20_Median + PercentSilence_Praat + Srh2_Mean + MCEP11_IQR + HarmonicProductSpectrum_SD + VAD_Mean + MCEP17_Mean + CepstralPeakProminence_SD + HMPDD4_MAD + MCEP23_Mean + HMPDM15_Median + Srh1_Mean + MCEP18_Mean + MeanTurnDur_Praat + MCEP22_Median + HMPDM13_Median + HMPDD6_SD + HMPDM16_Median + MCEP18_IQR + (1|NewID))

FormulaDf_2lr <- bf(Diagnosis~1  + Clarity_Mean + MCEP1_Median + MCEP1_SD + NewID + peakSlope_SD + MCEP8_Mean + HarmonicProductSpectrum_Mean + F0_Mean_Praat + MCEP6_Mean + HMPDD0_MAD + Rd_conf_Median + MCEP5_Mean + MCEP13_Mean + MCEP0_SD + peakSlope_IQR + HMPDD7_Median + Srh2_SD + Intensity_SD_Praat + MeanPauseDur_Cova + MCEP12_Median + F1_IQR + HMPDD6_Mean + TurnDuration_Cova + Intensity_Mean_Praat + MCEP4_Median + HMPDD0_SD + Rd_Mean + PauseNumMin_Praat + MCEP15_Mean + PauseDuration_Praat + MCEP8_IQR + MCEP20_Median + PercentSilence_Praat + Srh2_Mean + MCEP11_IQR + HarmonicProductSpectrum_SD + VAD_Mean + MCEP17_Mean + CepstralPeakProminence_SD + HMPDD4_MAD + MCEP23_Mean + HMPDM15_Median + Srh1_Mean + MCEP18_Mean + MeanTurnDur_Praat + MCEP22_Median + HMPDM13_Median + HMPDD6_SD + HMPDM16_Median + MCEP18_IQR + MCEP21_IQR + Clarity_SD + MCEP13_IQR + MCEP1_IQR + MCEP2_Mean + MCEP0_IQR + HMPDM18_Median + HMPDM20_Median + HMPDD12_MAD + HMPDM19_IQR + PSP_SD + HMPDM11_IQR + HMPDD1_MAD + HMPDM13_IQR + HMPDM12_MAD + MCEP21_Median + QOQ_IQR + MCEP16_Mean + MCEP17_IQR + MCEP2_IQR + (1|NewID))

# Formula svm
FormulaDf_0svm <- bf(Diagnosis~1  +  NewID + MCEP13_Mean + MCEP12_Median + MCEP20_Median + MCEP15_Mean + HMPDD0_MAD + Clarity_Mean + MCEP1_SD + Harmonicity_SD + MCEP8_Mean + HMPDD0_SD + MCEP8_IQR + MCEP11_IQR + CepstralPeakProminence_SD + Intensity_SD_Praat + MCEP16_Mean + F2_MAD + MCEP5_Mean + MCEP6_Mean + HMPDM13_Median + MCEP23_Mean + MCEP18_Mean + QOQ_SD + MCEP7_IQR + HMPDM16_Median + PauseNumMin_Praat + MCEP9_Mean + creakF0_SD + F1_IQR + NHR_mean  +  (1|NewID))

FormulaDf_1svm <- bf(Diagnosis~1  +  NewID + MCEP13_Mean + MCEP12_Median + MCEP20_Median + MCEP15_Mean + HMPDD0_MAD + Clarity_Mean + MCEP1_SD + Harmonicity_SD + MCEP8_Mean + HMPDD0_SD + MCEP8_IQR + MCEP11_IQR + CepstralPeakProminence_SD + Intensity_SD_Praat + MCEP16_Mean + F2_MAD + MCEP5_Mean + MCEP6_Mean + HMPDM13_Median + MCEP23_Mean + MCEP18_Mean + QOQ_SD + MCEP7_IQR + HMPDM16_Median + PauseNumMin_Praat + MCEP9_Mean + creakF0_SD + F1_IQR + NHR_mean + PercentSilence_Praat + TurnDuration_Cova + HMPDM18_Median + MeanPauseDur_Cova + TurnNumMin_Cova + MCEP2_IQR + H1H2_MAD + Srh1_Mean + HMPDM22_MAD + MCEP2_Mean + HarmonicProductSpectrum_SD + HMPDM10_IQR + MeanTurnDur_Praat + HMPDM21_MAD + Pitch_IQR + MCEP0_SD + MCEP13_IQR + F0_Mean_Praat + MCEP1_Median + HMPDM13_IQR +  (1|NewID))

FormulaDf_2svm <- bf(Diagnosis~1  + NewID + MCEP13_Mean + MCEP12_Median + MCEP20_Median + MCEP15_Mean + HMPDD0_MAD + Clarity_Mean + MCEP1_SD + Harmonicity_SD + MCEP8_Mean + HMPDD0_SD + MCEP8_IQR + MCEP11_IQR + CepstralPeakProminence_SD + Intensity_SD_Praat + MCEP16_Mean + F2_MAD + MCEP5_Mean + MCEP6_Mean + HMPDM13_Median + MCEP23_Mean + MCEP18_Mean + QOQ_SD + MCEP7_IQR + HMPDM16_Median + PauseNumMin_Praat + MCEP9_Mean + creakF0_SD + F1_IQR + NHR_mean + PercentSilence_Praat + TurnDuration_Cova + HMPDM18_Median + MeanPauseDur_Cova + TurnNumMin_Cova + MCEP2_IQR + H1H2_MAD + Srh1_Mean + HMPDM22_MAD + MCEP2_Mean + HarmonicProductSpectrum_SD + HMPDM10_IQR + MeanTurnDur_Praat + HMPDM21_MAD + Pitch_IQR + MCEP0_SD + MCEP13_IQR + F0_Mean_Praat + MCEP1_Median + HMPDM13_IQR + MCEP15_IQR + HRF_IQR + MCEP0_Median + MCEP6_IQR + F1_Median + HMPDM20_IQR + HMPDD6_SD + MCEP5_IQR + F0_SD_Praat + Rd_conf_SD + HMPDM11_IQR + MCEP9_IQR + MDQ_SD + MCEP21_IQR + HMPDM19_Median + MCEP18_IQR + MCEP19_IQR + NAQ_Median + HMPDD1_MAD + MeanTurnDur_Cova + (1|NewID))


# Formula boosted trees
FormulaDf_0bt <- bf(Diagnosis~1  +  MCEP8_Mean + NewID + MCEP7_Mean + MCEP11_Median + F0_SD_Praat + MCEP20_Median + Harmonicity_SD + CepstralPeakProminence_SD + MCEP17_Mean + MCEP15_Mean + PercentSilence_Praat + MCEP18_Mean + HMPDD0_SD + Rd_conf_Median + MCEP11_IQR + MCEP4_Median + TurnNumMin_Cova + MCEP23_Mean + MCEP2_Mean + Pitch_IQR + MCEP13_Mean + MCEP3_IQR + MCEP1_SD + Clarity_Mean + LPerror_Mean + MCEP5_Mean + MCEP1_IQR + NAQ_Median + HMPDM10_IQR + Intensity_SD_Praat  +  (1|NewID))

FormulaDf_1bt <- bf(Diagnosis~1  + MCEP8_Mean + NewID + MCEP7_Mean + MCEP11_Median + F0_SD_Praat + MCEP20_Median + Harmonicity_SD + CepstralPeakProminence_SD + MCEP17_Mean + MCEP15_Mean + PercentSilence_Praat + MCEP18_Mean + HMPDD0_SD + Rd_conf_Median + MCEP11_IQR + MCEP4_Median + TurnNumMin_Cova + MCEP23_Mean + MCEP2_Mean + Pitch_IQR + MCEP13_Mean + MCEP3_IQR + MCEP1_SD + Clarity_Mean + LPerror_Mean + MCEP5_Mean + MCEP1_IQR + NAQ_Median + HMPDM10_IQR + Intensity_SD_Praat + CreakProbability_SD + MCEP21_Median + MCEP16_Mean + F1_Median + LPerror_SD + HMPDM13_Median + MCEP0_SD + F1_IQR + F0_Mean_Praat + HMPDM24_SD + HMPDD6_Mean + MCEP14_Mean + MDQ_Median + MCEP7_IQR + HMPDD7_Median + HMPDD0_MAD + F2_MAD + MeanTurnDur_Cova + HMPDM15_Median + HMPDM21_Median + (1|NewID))

FormulaDf_2bt <- bf(Diagnosis~1  +  MCEP8_Mean + NewID + MCEP7_Mean + MCEP11_Median + F0_SD_Praat + MCEP20_Median + Harmonicity_SD + CepstralPeakProminence_SD + MCEP17_Mean + MCEP15_Mean + PercentSilence_Praat + MCEP18_Mean + HMPDD0_SD + Rd_conf_Median + MCEP11_IQR + MCEP4_Median + TurnNumMin_Cova + MCEP23_Mean + MCEP2_Mean + Pitch_IQR + MCEP13_Mean + MCEP3_IQR + MCEP1_SD + Clarity_Mean + LPerror_Mean + MCEP5_Mean + MCEP1_IQR + NAQ_Median + HMPDM10_IQR + Intensity_SD_Praat + CreakProbability_SD + MCEP21_Median + MCEP16_Mean + F1_Median + LPerror_SD + HMPDM13_Median + MCEP0_SD + F1_IQR + F0_Mean_Praat + HMPDM24_SD + HMPDD6_Mean + MCEP14_Mean + MDQ_Median + MCEP7_IQR + HMPDD7_Median + HMPDD0_MAD + F2_MAD + MeanTurnDur_Cova + HMPDM15_Median + HMPDM21_Median + MCEP9_Mean + MCEP6_IQR + HMPDM19_IQR + TurnDuration_Cova + MCEP15_IQR + MCEP6_Mean + VAD_Mean + Pitch_SD + HMPDD3_MAD + MCEP1_Median + MCEP17_IQR + MCEP2_IQR + HMPDM20_Median + MCEP12_Median + MCEP9_IQR + HMPDM12_MAD + HMPDM16_Median + MeanTurnDur_Praat + MCEP8_IQR + MCEP22_Median + (1|NewID))

# Prior
EDf_p <- c(
  brms::prior(normal(0,1),class=Intercept),
  brms::prior(normal(0,1),class=b),
  brms::prior(normal(0,.1),class=sd)
)

#get_prior(FormulaDf_1,family=bernoulli,data=EDf)

# Prior for 3 models for logreg
EDf_m_0lr <- brm(
  FormulaDf_0lr,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

EDf_m_1lr <- brm(
  FormulaDf_1lr,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

EDf_m_2lr <- brm(
  FormulaDf_2lr,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

# Prior for 3 models for svm
EDf_m_0svm <- brm(
  FormulaDf_0svm,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

EDf_m_1svm <- brm(
  FormulaDf_1svm,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

EDf_m_2svm <- brm(
  FormulaDf_2svm,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

# Prior for 3 models for boostrees
EDf_m_0bt <- brm(
  FormulaDf_0bt,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

EDf_m_1bt <- brm(
  FormulaDf_1bt,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)

EDf_m_2bt <- brm(
  FormulaDf_2bt,
  trainEDf,
  family = bernoulli,
  prior = EDf_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(4)
)


zlr <- pp_check(EDf_m_0lr, ndraws = 100) + labs(title="Prior predictive checks emprical data, log reg, model with top 30 variables")
olr <- pp_check(EDf_m_1lr, ndraws = 100) + labs(title="Prior predictive checks emprical data, log reg, model with top 50 variables")
tlr <- pp_check(EDf_m_2lr, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, log reg, model with top 70 variables")

zsvm <- pp_check(EDf_m_0svm, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, svm, model with top 30 variables")
osvm <- pp_check(EDf_m_1svm, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, svm, model with top 50 variables")
tsvm <- pp_check(EDf_m_2svm, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, svm, model with top 70 variables")

zbt <- pp_check(EDf_m_0bt, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, bt, model with top 30 variables")
obt <- pp_check(EDf_m_1bt, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, bt, model with top 50 variables")
tbt <- pp_check(EDf_m_2bt, ndraws = 100)  +  labs(title="Prior predictive checks emprical data, bt, model with top 70 variables")

grid.arrange(zlr, olr, tlr)
grid.arrange(zsvm, osvm, tsvm)
grid.arrange(zbt, obt, tbt)
```


### Doing the fit, posterior
```{r}
# For logreg
EDf_post_0lr <-
  brm(
    FormulaDf_0lr,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

EDf_post_1lr <-
  brm(
    FormulaDf_1lr,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

EDf_post_2lr <-
  brm(
    FormulaDf_2lr,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

# For svm
EDf_post_0svm <-
  brm(
    FormulaDf_0svm,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

EDf_post_1svm <-
  brm(
    FormulaDf_1svm,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

EDf_post_2svm <-
  brm(
    FormulaDf_2svm,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

# For bt
EDf_post_0bt <-
  brm(
    FormulaDf_0bt,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

EDf_post_1bt <-
  brm(
    FormulaDf_1bt,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )

EDf_post_2bt <-
  brm(
    FormulaDf_2bt,
    trainEDf,
    save_pars = save_pars(all = TRUE),
    family = bernoulli,
    prior = EDf_p,
    sample_prior = T,
    iter = 2000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4)
  )
```


### Plots drawing from posterior, posterior update plots
```{r}
posteriorEDf_0lr <- as_draws_df(EDf_post_0lr)
posteriorEDf_1lr <- as_draws_df(EDf_post_1lr)
posteriorEDf_2lr <- as_draws_df(EDf_post_2lr)

posteriorEDf_0svm <- as_draws_df(EDf_post_0svm)
posteriorEDf_1svm <- as_draws_df(EDf_post_1svm)
posteriorEDf_2svm <- as_draws_df(EDf_post_2svm)

posteriorEDf_0bt <- as_draws_df(EDf_post_0bt)
posteriorEDf_1bt <- as_draws_df(EDf_post_1bt)
posteriorEDf_2bt <- as_draws_df(EDf_post_2bt)

# Posterior drawings
pos_0lr <- 
  select(posteriorEDf_0lr, c("b_Clarity_Mean","b_MCEP1_Median","b_MCEP1_SD","b_NewID","b_peakSlope_SD","b_MCEP8_Mean","b_HarmonicProductSpectrum_Mean","b_F0_Mean_Praat","b_MCEP6_Mean","b_HMPDD0_MAD","b_Rd_conf_Median","b_MCEP5_Mean","b_MCEP13_Mean","b_MCEP0_SD","b_peakSlope_IQR","b_HMPDD7_Median","b_Srh2_SD","b_Intensity_SD_Praat","b_MeanPauseDur_Cova","b_MCEP12_Median","b_F1_IQR","b_HMPDD6_Mean","b_TurnDuration_Cova","b_Intensity_Mean_Praat","b_MCEP4_Median","b_HMPDD0_SD","b_Rd_Mean","b_PauseNumMin_Praat","b_MCEP15_Mean","b_PauseDuration_Praat")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

pos_1lr <- 
  select(posteriorEDf_1lr, c("b_Clarity_Mean","b_MCEP1_Median","b_MCEP1_SD","b_NewID","b_peakSlope_SD","b_MCEP8_Mean","b_HarmonicProductSpectrum_Mean","b_F0_Mean_Praat","b_MCEP6_Mean","b_HMPDD0_MAD","b_Rd_conf_Median","b_MCEP5_Mean","b_MCEP13_Mean","b_MCEP0_SD","b_peakSlope_IQR","b_HMPDD7_Median","b_Srh2_SD","b_Intensity_SD_Praat","b_MeanPauseDur_Cova","b_MCEP12_Median","b_F1_IQR","b_HMPDD6_Mean","b_TurnDuration_Cova","b_Intensity_Mean_Praat","b_MCEP4_Median","b_HMPDD0_SD","b_Rd_Mean","b_PauseNumMin_Praat","b_MCEP15_Mean","b_PauseDuration_Praat","b_MCEP8_IQR", "b_MCEP20_Median", "b_PercentSilence_Praat", "b_Srh2_Mean", "b_MCEP11_IQR", "b_HarmonicProductSpectrum_SD", "b_VAD_Mean", "b_MCEP17_Mean", "b_CepstralPeakProminence_SD", "b_HMPDD4_MAD", "b_MCEP23_Mean", "b_HMPDM15_Median", "b_Srh1_Mean", "b_MCEP18_Mean", "b_MeanTurnDur_Praat", "b_MCEP22_Median", "b_HMPDM13_Median", "b_HMPDD6_SD", "b_HMPDM16_Median", "b_MCEP18_IQR")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

pos_2lr <- 
  select(posteriorEDf_2lr, c("b_Clarity_Mean","b_MCEP1_Median","b_MCEP1_SD","b_NewID","b_peakSlope_SD","b_MCEP8_Mean","b_HarmonicProductSpectrum_Mean","b_F0_Mean_Praat","b_MCEP6_Mean","b_HMPDD0_MAD","b_Rd_conf_Median","b_MCEP5_Mean","b_MCEP13_Mean","b_MCEP0_SD","b_peakSlope_IQR","b_HMPDD7_Median","b_Srh2_SD","b_Intensity_SD_Praat","b_MeanPauseDur_Cova","b_MCEP12_Median","b_F1_IQR","b_HMPDD6_Mean","b_TurnDuration_Cova","b_Intensity_Mean_Praat","b_MCEP4_Median","b_HMPDD0_SD","b_Rd_Mean","b_PauseNumMin_Praat","b_MCEP15_Mean","b_PauseDuration_Praat","b_MCEP8_IQR", "b_MCEP20_Median", "b_PercentSilence_Praat", "b_Srh2_Mean", "b_MCEP11_IQR", "b_HarmonicProductSpectrum_SD", "b_VAD_Mean", "b_MCEP17_Mean", "b_CepstralPeakProminence_SD", "b_HMPDD4_MAD", "b_MCEP23_Mean", "b_HMPDM15_Median", "b_Srh1_Mean", "b_MCEP18_Mean", "b_MeanTurnDur_Praat", "b_MCEP22_Median", "b_HMPDM13_Median", "b_HMPDD6_SD", "b_HMPDM16_Median", "b_MCEP18_IQR","b_MCEP21_IQR", "b_Clarity_SD", "b_MCEP13_IQR", "b_MCEP1_IQR", "b_MCEP2_Mean", "b_MCEP0_IQR", "b_HMPDM18_Median", "b_HMPDM20_Median", "b_HMPDD12_MAD", "b_HMPDM19_IQR", "b_PSP_SD", "b_HMPDM11_IQR", "b_HMPDD1_MAD", "b_HMPDM13_IQR", "b_HMPDM12_MAD", "b_MCEP21_Median", "b_QOQ_IQR", "b_MCEP16_Mean", "b_MCEP17_IQR", "b_MCEP2_IQR")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

# svm
pos_0svm <- 
  select(posteriorEDf_0svm, c("b_NewID", "b_MCEP13_Mean", "b_MCEP12_Median", "b_MCEP20_Median", "b_MCEP15_Mean", "b_HMPDD0_MAD", "b_Clarity_Mean", "b_MCEP1_SD", "b_Harmonicity_SD", "b_MCEP8_Mean", "b_HMPDD0_SD", "b_MCEP8_IQR", "b_MCEP11_IQR", "b_CepstralPeakProminence_SD", "b_Intensity_SD_Praat", "b_MCEP16_Mean", "b_F2_MAD", "b_MCEP5_Mean", "b_MCEP6_Mean", "b_HMPDM13_Median", "b_MCEP23_Mean", "b_MCEP18_Mean", "b_QOQ_SD", "b_MCEP7_IQR", "b_HMPDM16_Median", "b_PauseNumMin_Praat", "b_MCEP9_Mean", "b_creakF0_SD", "b_F1_IQR", "b_NHR_mean")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

pos_1svm <- 
  select(posteriorEDf_1svm, c("b_NewID", "b_MCEP13_Mean", "b_MCEP12_Median", "b_MCEP20_Median", "b_MCEP15_Mean", "b_HMPDD0_MAD", "b_Clarity_Mean", "b_MCEP1_SD", "b_Harmonicity_SD", "b_MCEP8_Mean", "b_HMPDD0_SD", "b_MCEP8_IQR", "b_MCEP11_IQR", "b_CepstralPeakProminence_SD", "b_Intensity_SD_Praat", "b_MCEP16_Mean", "b_F2_MAD", "b_MCEP5_Mean", "b_MCEP6_Mean", "b_HMPDM13_Median", "b_MCEP23_Mean", "b_MCEP18_Mean", "b_QOQ_SD", "b_MCEP7_IQR", "b_HMPDM16_Median", "b_PauseNumMin_Praat", "b_MCEP9_Mean", "b_creakF0_SD", "b_F1_IQR", "b_NHR_mean", "b_PercentSilence_Praat", "b_TurnDuration_Cova", "b_HMPDM18_Median", "b_MeanPauseDur_Cova", "b_TurnNumMin_Cova", "b_MCEP2_IQR", "b_H1H2_MAD", "b_Srh1_Mean", "b_HMPDM22_MAD", "b_MCEP2_Mean", "b_HarmonicProductSpectrum_SD", "b_HMPDM10_IQR", "b_MeanTurnDur_Praat", "b_HMPDM21_MAD", "b_Pitch_IQR", "b_MCEP0_SD", "b_MCEP13_IQR", "b_F0_Mean_Praat", "b_MCEP1_Median", "b_HMPDM13_IQR")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

pos_2svm <- 
  select(posteriorEDf_2svm, c("b_NewID", "b_MCEP13_Mean", "b_MCEP12_Median", "b_MCEP20_Median", "b_MCEP15_Mean", "b_HMPDD0_MAD", "b_Clarity_Mean", "b_MCEP1_SD", "b_Harmonicity_SD", "b_MCEP8_Mean", "b_HMPDD0_SD", "b_MCEP8_IQR", "b_MCEP11_IQR", "b_CepstralPeakProminence_SD", "b_Intensity_SD_Praat", "b_MCEP16_Mean", "b_F2_MAD", "b_MCEP5_Mean", "b_MCEP6_Mean", "b_HMPDM13_Median", "b_MCEP23_Mean", "b_MCEP18_Mean", "b_QOQ_SD", "b_MCEP7_IQR", "b_HMPDM16_Median", "b_PauseNumMin_Praat", "b_MCEP9_Mean", "b_creakF0_SD", "b_F1_IQR", "b_NHR_mean", "b_PercentSilence_Praat", "b_TurnDuration_Cova", "b_HMPDM18_Median", "b_MeanPauseDur_Cova", "b_TurnNumMin_Cova", "b_MCEP2_IQR", "b_H1H2_MAD", "b_Srh1_Mean", "b_HMPDM22_MAD", "b_MCEP2_Mean", "b_HarmonicProductSpectrum_SD", "b_HMPDM10_IQR", "b_MeanTurnDur_Praat", "b_HMPDM21_MAD", "b_Pitch_IQR", "b_MCEP0_SD", "b_MCEP13_IQR", "b_F0_Mean_Praat", "b_MCEP1_Median", "b_HMPDM13_IQR", "b_MCEP15_IQR", "b_HRF_IQR", "b_MCEP0_Median", "b_MCEP6_IQR", "b_F1_Median", "b_HMPDM20_IQR", "b_HMPDD6_SD", "b_MCEP5_IQR", "b_F0_SD_Praat", "b_Rd_conf_SD", "b_HMPDM11_IQR", "b_MCEP9_IQR", "b_MDQ_SD", "b_MCEP21_IQR", "b_HMPDM19_Median", "b_MCEP18_IQR", "b_MCEP19_IQR", "b_NAQ_Median", "b_HMPDD1_MAD", "b_MeanTurnDur_Cova")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

#bt
pos_0bt <- 
  select(posteriorEDf_0bt, c("b_MCEP8_Mean", "b_NewID", "b_MCEP7_Mean", "b_MCEP11_Median", "b_F0_SD_Praat", "b_MCEP20_Median", "b_Harmonicity_SD", "b_CepstralPeakProminence_SD", "b_MCEP17_Mean", "b_MCEP15_Mean", "b_PercentSilence_Praat", "b_MCEP18_Mean", "b_HMPDD0_SD", "b_Rd_conf_Median", "b_MCEP11_IQR", "b_MCEP4_Median", "b_TurnNumMin_Cova", "b_MCEP23_Mean", "b_MCEP2_Mean", "b_Pitch_IQR", "b_MCEP13_Mean", "b_MCEP3_IQR", "b_MCEP1_SD", "b_Clarity_Mean", "b_LPerror_Mean", "b_MCEP5_Mean", "b_MCEP1_IQR", "b_NAQ_Median", "b_HMPDM10_IQR", "b_Intensity_SD_Praat")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

pos_1bt <- 
  select(posteriorEDf_1bt, c("b_MCEP8_Mean", "b_NewID", "b_MCEP7_Mean", "b_MCEP11_Median", "b_F0_SD_Praat", "b_MCEP20_Median", "b_Harmonicity_SD", "b_CepstralPeakProminence_SD", "b_MCEP17_Mean", "b_MCEP15_Mean", "b_PercentSilence_Praat", "b_MCEP18_Mean", "b_HMPDD0_SD", "b_Rd_conf_Median", "b_MCEP11_IQR", "b_MCEP4_Median", "b_TurnNumMin_Cova", "b_MCEP23_Mean", "b_MCEP2_Mean", "b_Pitch_IQR", "b_MCEP13_Mean", "b_MCEP3_IQR", "b_MCEP1_SD", "b_Clarity_Mean", "b_LPerror_Mean", "b_MCEP5_Mean", "b_MCEP1_IQR", "b_NAQ_Median", "b_HMPDM10_IQR", "b_Intensity_SD_Praat", "b_CreakProbability_SD", "b_MCEP21_Median", "b_MCEP16_Mean", "b_F1_Median", "b_LPerror_SD", "b_HMPDM13_Median", "b_MCEP0_SD", "b_F1_IQR", "b_F0_Mean_Praat", "b_HMPDM24_SD", "b_HMPDD6_Mean", "b_MCEP14_Mean", "b_MDQ_Median", "b_MCEP7_IQR", "b_HMPDD7_Median", "b_HMPDD0_MAD", "b_F2_MAD", "b_MeanTurnDur_Cova", "b_HMPDM15_Median", "b_HMPDM21_Median")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

pos_2bt <- 
  select(posteriorEDf_2bt, c("b_MCEP8_Mean", "b_NewID", "b_MCEP7_Mean", "b_MCEP11_Median", "b_F0_SD_Praat", "b_MCEP20_Median", "b_Harmonicity_SD", "b_CepstralPeakProminence_SD", "b_MCEP17_Mean", "b_MCEP15_Mean", "b_PercentSilence_Praat", "b_MCEP18_Mean", "b_HMPDD0_SD", "b_Rd_conf_Median", "b_MCEP11_IQR", "b_MCEP4_Median", "b_TurnNumMin_Cova", "b_MCEP23_Mean", "b_MCEP2_Mean", "b_Pitch_IQR", "b_MCEP13_Mean", "b_MCEP3_IQR", "b_MCEP1_SD", "b_Clarity_Mean", "b_LPerror_Mean", "b_MCEP5_Mean", "b_MCEP1_IQR", "b_NAQ_Median", "b_HMPDM10_IQR", "b_Intensity_SD_Praat", "b_CreakProbability_SD", "b_MCEP21_Median", "b_MCEP16_Mean", "b_F1_Median", "b_LPerror_SD", "b_HMPDM13_Median", "b_MCEP0_SD", "b_F1_IQR", "b_F0_Mean_Praat", "b_HMPDM24_SD", "b_HMPDD6_Mean", "b_MCEP14_Mean", "b_MDQ_Median", "b_MCEP7_IQR", "b_HMPDD7_Median", "b_HMPDD0_MAD", "b_F2_MAD", "b_MeanTurnDur_Cova", "b_HMPDM15_Median", "b_HMPDM21_Median", "b_MCEP9_Mean", "b_MCEP6_IQR", "b_HMPDM19_IQR", "b_TurnDuration_Cova", "b_MCEP15_IQR", "b_MCEP6_Mean", "b_VAD_Mean", "b_Pitch_SD", "b_HMPDD3_MAD", "b_MCEP1_Median", "b_MCEP17_IQR", "b_MCEP2_IQR", "b_HMPDM20_Median", "b_MCEP12_Median", "b_MCEP9_IQR", "b_HMPDM12_MAD", "b_HMPDM16_Median", "b_MeanTurnDur_Praat", "b_MCEP8_IQR", "b_MCEP22_Median")) %>% 
  mutate(tall=1) %>% 
  reshape2::melt(id.vars='tall')

# Logreg
lrp0 <- ggplot() + 
  geom_density(data=pos_0lr, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model30, logreg')+ theme(legend.position = "none")  

lrp1 <-ggplot() + 
  geom_density(data=pos_1lr, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model50,logreg')+ theme(legend.position = "none")  

lrp2 <-ggplot() + 
  geom_density(data=pos_2lr, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model70,logreg')+ theme(legend.position = "none")  

# SVM
svmp0 <- ggplot() + 
  geom_density(data=pos_0svm, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model30, svm')+ theme(legend.position = "none")  

svmp1 <- ggplot() + 
  geom_density(data=pos_1svm, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model50,svm')+ theme(legend.position = "none")  

svmp2 <- ggplot() + 
  geom_density(data=pos_2svm, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model70,svm')+ theme(legend.position = "none")  

# bt
btp0 <- ggplot() + 
  geom_density(data=pos_0bt, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model30, bt')+ theme(legend.position = "none")  

btp1 <- ggplot() + 
  geom_density(data=pos_1bt, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model50,bt') + theme(legend.position = "none")  

btp2 <- ggplot() + 
  geom_density(data=pos_2bt, aes(x=value, color=variable, fill=variable), alpha=0.3) + 
  xlim(-4,5) + 
  ylim(0,7.5) + 
  xlab('Estimates') + 
  ggtitle('Posterior for model70,bt') + theme(legend.position = "none") 


grid.arrange(lrp0,lrp1,lrp2,top = "Posterior draws from models with logreg feature selection")
grid.arrange(svmp0,svmp1,svmp2,top = "Posterior draws from models with svm feature selection")
grid.arrange(btp0,btp1,btp2,top = "Posterior draws from models with bt feature selection")
```


### Generating average predictions
```{r}
# generate average predictions

# model30
# logreg
trainEDf$PredictionsPerc0lr <-  predict(EDf_post_0lr)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc0lr > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc0lr <= 0.5] <- "CT"

testEDf$PredictionsPerc0lr <- predict(EDf_post_0lr,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc0lr > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc0lr <= 0.5] <- "CT"

# svm
trainEDf$PredictionsPerc0svm <-  predict(EDf_post_0svm)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc0svm > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc0svm <= 0.5] <- "CT"

testEDf$PredictionsPerc0svm <- predict(EDf_post_0svm,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc0svm > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc0svm <= 0.5] <- "CT"


# bt
trainEDf$PredictionsPerc0bt <-  predict(EDf_post_0bt)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc0bt > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc0bt <= 0.5] <- "CT"

testEDf$PredictionsPerc0bt <- predict(EDf_post_0bt,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc0bt > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc0bt <= 0.5] <- "CT"

# model50
# logreg
trainEDf$PredictionsPerc1lr <-  predict(EDf_post_1lr)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc1lr > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc1lr <= 0.5] <- "CT"

testEDf$PredictionsPerc1lr <- predict(EDf_post_1lr,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc1lr > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc1lr <= 0.5] <- "CT"

#svm
trainEDf$PredictionsPerc1svm <-  predict(EDf_post_1svm)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc1svm > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc1svm <= 0.5] <- "CT"

testEDf$PredictionsPerc1svm <- predict(EDf_post_1svm,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc1svm > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc1svm <= 0.5] <- "CT"

#bt
trainEDf$PredictionsPerc1bt <-  predict(EDf_post_1bt)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc1bt > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc1bt <= 0.5] <- "CT"

testEDf$PredictionsPerc1bt <- predict(EDf_post_1bt,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc1bt > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc1bt <= 0.5] <- "CT"

# model70
# log reg
trainEDf$PredictionsPerc2lr <-  predict(EDf_post_2lr)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc2lr > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc2lr <= 0.5] <- "CT"

testEDf$PredictionsPerc2lr <- predict(EDf_post_2lr,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc2lr > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc2lr <= 0.5] <- "CT"

# svm
trainEDf$PredictionsPerc2svm <-  predict(EDf_post_2svm)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc2svm > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc2svm <= 0.5] <- "CT"

testEDf$PredictionsPerc2svm <- predict(EDf_post_2svm,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc2svm > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc2svm <= 0.5] <- "CT"

# bt
trainEDf$PredictionsPerc2bt <-  predict(EDf_post_2bt)[, 1]
trainEDf$Predictions[trainEDf$PredictionsPerc2bt > 0.5] <- "SCZ"
trainEDf$Predictions[trainEDf$PredictionsPerc2bt <= 0.5] <- "CT"

testEDf$PredictionsPerc2bt <- predict(EDf_post_2bt,newdata = testEDf,allow_new_levels = T)[, 1]
testEDf$Predictions[testEDf$PredictionsPerc2bt > 0.5] <- "SCZ"
testEDf$Predictions[testEDf$PredictionsPerc2bt <= 0.5] <- "CT"
```

```{R}
## Now with uncertainty
pacman::p_load(tidyverse)

PerformanceProbEDf <- tibble(expand_grid(
  Sample = seq(2000),
  Model = c("Model30","Model50","Model70"),
  Setup = c("logreg","SVM","BT"),
  Type = c("training","test"))
)
# posterior predict for training

train0lr <- inv_logit_scaled(posterior_linpred(EDf_post_0lr,summary = F))
train1lr <- inv_logit_scaled(posterior_linpred(EDf_post_1lr,summary = F))
train2lr <- inv_logit_scaled(posterior_linpred(EDf_post_2lr,summary = F))

train0svm <- inv_logit_scaled(posterior_linpred(EDf_post_0svm,summary = F))
train1svm <- inv_logit_scaled(posterior_linpred(EDf_post_1svm,summary = F))
train2svm <- inv_logit_scaled(posterior_linpred(EDf_post_2svm,summary = F))

train0bt <- inv_logit_scaled(posterior_linpred(EDf_post_0bt,summary = F))
train1bt <- inv_logit_scaled(posterior_linpred(EDf_post_1bt,summary = F))
train2bt <- inv_logit_scaled(posterior_linpred(EDf_post_2bt,summary = F))

# same but for test
test0lr <- inv_logit_scaled(posterior_linpred(EDf_post_0lr,summary = F, newdata = testEDf,allow_new_levels = T))
test1lr <- inv_logit_scaled(posterior_linpred(EDf_post_1lr,summary = F, newdata = testEDf,allow_new_levels = T))
test2lr <- inv_logit_scaled(posterior_linpred(EDf_post_2lr,summary = F, newdata = testEDf,allow_new_levels = T))

test0svm <- inv_logit_scaled(posterior_linpred(EDf_post_0svm,summary = F, newdata = testEDf,allow_new_levels = T))
test1svm <- inv_logit_scaled(posterior_linpred(EDf_post_1svm,summary = F, newdata = testEDf,allow_new_levels = T))
test2svm <- inv_logit_scaled(posterior_linpred(EDf_post_2svm,summary = F, newdata = testEDf,allow_new_levels = T))

test0bt <- inv_logit_scaled(posterior_linpred(EDf_post_0bt,summary = F, newdata = testEDf,allow_new_levels = T))
test1bt <- inv_logit_scaled(posterior_linpred(EDf_post_1bt,summary = F, newdata = testEDf,allow_new_levels = T))
test2bt <- inv_logit_scaled(posterior_linpred(EDf_post_2bt,summary = F, newdata = testEDf,allow_new_levels = T))


for (i in seq(2000)){
  # inserting the predictions into the df for informed and skeptic
  trainEDf$Predictions0lr <- as.factor(ifelse(train0lr[i,] > 0.5, "SCZ","CT"))
  trainEDf$Predictions1lr <- as.factor(ifelse(train1lr[i,] > 0.5, "SCZ","CT"))
  trainEDf$Predictions2lr <- as.factor(ifelse(train2lr[i,] > 0.5, "SCZ","CT"))

  testEDf$Predictions0lr <- as.factor(ifelse(test0lr[i,] > 0.5, "SCZ","CT"))
  testEDf$Predictions1lr <- as.factor(ifelse(test1lr[i,] > 0.5, "SCZ","CT"))
  testEDf$Predictions2lr <- as.factor(ifelse(test2lr[i,] > 0.5, "SCZ","CT"))
  
  trainEDf$Predictions0svm <- as.factor(ifelse(train0svm[i,] > 0.5, "SCZ","CT"))
  trainEDf$Predictions1svm <- as.factor(ifelse(train1svm[i,] > 0.5, "SCZ","CT"))
  trainEDf$Predictions2svm <- as.factor(ifelse(train2svm[i,] > 0.5, "SCZ","CT"))

  testEDf$Predictions0svm <- as.factor(ifelse(test0svm[i,] > 0.5, "SCZ","CT"))
  testEDf$Predictions1svm <- as.factor(ifelse(test1svm[i,] > 0.5, "SCZ","CT"))
  testEDf$Predictions2svm <- as.factor(ifelse(test2svm[i,] > 0.5, "SCZ","CT"))
  
  trainEDf$Predictions0bt <- as.factor(ifelse(train0bt[i,] > 0.5, "SCZ","CT"))
  trainEDf$Predictions1bt <- as.factor(ifelse(train1bt[i,] > 0.5, "SCZ","CT"))
  trainEDf$Predictions2bt <- as.factor(ifelse(train2bt[i,] > 0.5, "SCZ","CT"))

  testEDf$Predictions0bt <- as.factor(ifelse(test0bt[i,] > 0.5, "SCZ","CT"))
  testEDf$Predictions1bt <- as.factor(ifelse(test1bt[i,] > 0.5, "SCZ","CT"))
  testEDf$Predictions2bt <- as.factor(ifelse(test2bt[i,] > 0.5, "SCZ","CT"))
  
  # put it into the performance prob df
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model30" & PerformanceProbEDf$Setup == "logreg" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions0lr)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model50" & PerformanceProbEDf$Setup == "logreg" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions1lr)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model70" & PerformanceProbEDf$Setup == "logreg" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions2lr)[,".estimate"]
  
  
   PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model30" & PerformanceProbEDf$Setup == "SVM" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions0svm)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model50" & PerformanceProbEDf$Setup == "SVM" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions1svm)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model70" & PerformanceProbEDf$Setup == "SVM" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions2svm)[,".estimate"]
  
  
   PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model30" & PerformanceProbEDf$Setup == "BT" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions0bt)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model50" & PerformanceProbEDf$Setup == "BT" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions1bt)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model70" & PerformanceProbEDf$Setup == "BT" & PerformanceProbEDf$Type == "training"] <- accuracy(trainEDf,truth = Diagnosis, estimate = Predictions2bt)[,".estimate"]
  
  # the same for tests
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model30" & PerformanceProbEDf$Setup == "logreg" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions0lr)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model50" & PerformanceProbEDf$Setup == "logreg" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions1lr)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model70" & PerformanceProbEDf$Setup == "logreg" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions2lr)[,".estimate"]
  
  
   PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model30" & PerformanceProbEDf$Setup == "SVM" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions0svm)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model50" & PerformanceProbEDf$Setup == "SVM" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions1svm)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model70" & PerformanceProbEDf$Setup == "SVM" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions2svm)[,".estimate"]
  
   PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model30" & PerformanceProbEDf$Setup == "BT" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions0bt)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model50" & PerformanceProbEDf$Setup == "BT" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions1bt)[,".estimate"]
  
  PerformanceProbEDf$Accuracy[PerformanceProbEDf$Sample == i & PerformanceProbEDf$Model == "Model70" & PerformanceProbEDf$Setup == "BT" & PerformanceProbEDf$Type == "test"] <- accuracy(testEDf,truth = Diagnosis, estimate = Predictions2bt)[,".estimate"]

}

PerformanceProbEDf$Accuracy <- as.numeric(PerformanceProbEDf$Accuracy)
```
### Plot of uncertainity of performance probablity of the different models
```{r}
ggplot(PerformanceProbEDf)  + 
  aes(x = Model, y = Accuracy, colour = Type)  + 
  facet_wrap(~Setup)  + 
  geom_point(shape=16,position = position_dodge(width = 0.5))  + 
  scale_color_hue(direction = 1)  + 
  theme_grey()
```
```{r}
PerformanceProbEDf %>%
  filter(Type == "test") %>% 
  group_by(Model, Setup) %>%
  summarize(Mean_Accuracy = mean(Accuracy),Min_acc = min(Accuracy),Max_acc = max(Accuracy),Range_acc = Max_acc - Min_acc)
```

```{r}
library(caret)


confusionMatrix(testEDf$Diagnosis,testEDf$Predictions0lr)
confusionMatrix(testEDf$Diagnosis,testEDf$Predictions1lr)
confusionMatrix(testEDf$Diagnosis,testEDf$Predictions2lr)

confusionMatrix(testEDf$Diagnosis,testEDf$Predictions0svm)
confusionMatrix(testEDf$Diagnosis,testEDf$Predictions1svm)
confusionMatrix(testEDf$Diagnosis,testEDf$Predictions2svm)

confusionMatrix(testEDf$Diagnosis,testEDf$Predictions0bt)
confusionMatrix(testEDf$Diagnosis,testEDf$Predictions1bt)
confusionMatrix(testEDf$Diagnosis,testEDf$Predictions2bt)

```
